{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vaex\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for removing collinear tables by threshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "\n",
    "def calculate_vif(X, thresh=10):\n",
    "    cols = X.columns\n",
    "    variables = np.arange(X.shape[1])\n",
    "    dropped=True\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        c = X[cols[variables]].values\n",
    "        vif = [variance_inflation_factor(c, ix) for ix in np.arange(c.shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        print('processed: ' + X[cols[variables]].columns[maxloc])\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X[cols[variables]].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
    "            variables = np.delete(variables, maxloc)\n",
    "            dropped=True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X[cols[variables]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = vaex.from_csv('final_dataset_new.csv', convert=True, chunk_size=5_000_000)\n",
    "#train_df = pd.read_csv(\"final_dataset_new.csv\", header=0)\n",
    "\n",
    "#lets sample out of the dataset so we can train quickly\n",
    "#train_df = train_df.sample(frac=0.05, random_state=786)\n",
    "\n",
    "#impute nans\n",
    "train_df = train_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 8090)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate labels\n",
    "target_category_to_set = 'OTHER'\n",
    "genres_to_aggregate = []\n",
    "\n",
    "#lets get genre counts\n",
    "genre_count = train_df.groupby(by='genre').agg({'genre':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hip-Hop</th>\n",
       "      <td>2265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>3516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimental Pop</th>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loud-Rock</th>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avant-Garde</th>\n",
       "      <td>5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nerdcore</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latin</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jungle</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkish</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spoken Word</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count\n",
       "genre                  \n",
       "Hip-Hop            2265\n",
       "Pop                3516\n",
       "Experimental Pop   1138\n",
       "Loud-Rock           251\n",
       "Avant-Garde        5252\n",
       "...                 ...\n",
       "Nerdcore              1\n",
       "Latin                 5\n",
       "Jungle               11\n",
       "Turkish               2\n",
       "Spoken Word           1\n",
       "\n",
       "[141 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_count = genre_count.to_pandas_df()\n",
    "genre_count = genre_count.set_index('genre')\n",
    "genre_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate sparse genres for list\n",
    "for index, row in genre_count.iterrows():\n",
    "    value = row['count']\n",
    "    #if value <= percent_to_aggregate_to_other * total_rows:\n",
    "    if value <= 10: \n",
    "        genres_to_aggregate.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate all rows, and all aggregation genres, and set to new category\n",
    "#when needed\n",
    "for index, row in train_df.iterrows():\n",
    "    for genre in genres_to_aggregate:\n",
    "        if row['genre'] == genre:\n",
    "            train_df.loc[index, 'genre'] = target_category_to_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df[\"genre\"].values\n",
    "train_df.drop([\"genre\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop: lowlevel_barkbands_flatness_db_mean with VIF = 13.411376529605432\n",
      "drop: lowlevel_barkbands_flatness_db_median with VIF = 11.956102304541915\n",
      "drop: lowlevel_barkbands_kurtosis_dmean with VIF = 254.0352366226337\n",
      "drop: lowlevel_barkbands_kurtosis_dmean2 with VIF = 66.33634735280998\n",
      "drop: lowlevel_barkbands_kurtosis_dvar with VIF = 43076.78513423729\n",
      "drop: lowlevel_barkbands_kurtosis_dvar2 with VIF = 11990.343903102275\n",
      "drop: lowlevel_barkbands_kurtosis_max with VIF = 89.48837763138212\n",
      "drop: lowlevel_barkbands_kurtosis_mean with VIF = 1498.8811023678047\n",
      "drop: lowlevel_barkbands_kurtosis_median with VIF = 720.1425141450057\n",
      "drop: lowlevel_barkbands_kurtosis_stdev with VIF = 215.20959787463806\n",
      "drop: lowlevel_barkbands_kurtosis_var with VIF = 4890.855132420988\n",
      "drop: lowlevel_barkbands_skewness_dmean with VIF = 16.76645612850121\n",
      "drop: lowlevel_barkbands_skewness_dmean2 with VIF = 18.09548518724244\n",
      "drop: lowlevel_barkbands_skewness_dvar with VIF = 172.16685735404315\n",
      "drop: lowlevel_barkbands_skewness_dvar2 with VIF = 67.76419216311977\n",
      "drop: lowlevel_barkbands_skewness_mean with VIF = 44.79788264743289\n",
      "drop: lowlevel_barkbands_skewness_median with VIF = 140.42353518966326\n",
      "drop: lowlevel_barkbands_skewness_min with VIF = 15.475112540801268\n",
      "drop: lowlevel_barkbands_skewness_stdev with VIF = 32.573193099428565\n",
      "drop: lowlevel_barkbands_skewness_var with VIF = 394.7092458428177\n",
      "drop: lowlevel_barkbands_spread_dmean with VIF = 25.622953052782638\n",
      "drop: lowlevel_barkbands_spread_dmean2 with VIF = 23.469179354291743\n",
      "drop: lowlevel_barkbands_spread_dvar with VIF = 14.895074357790325\n",
      "drop: lowlevel_barkbands_spread_dvar2 with VIF = 13.115273705172312\n",
      "drop: lowlevel_barkbands_spread_mean with VIF = 11.774171245672074\n",
      "drop: lowlevel_barkbands_spread_stdev with VIF = 11.78523563025323\n",
      "drop: lowlevel_erbbands_flatness_db_mean with VIF = 16.86338155488846\n",
      "drop: lowlevel_erbbands_flatness_db_median with VIF = 16.037443481543328\n",
      "drop: lowlevel_erbbands_kurtosis_dvar with VIF = 228.95458925638707\n",
      "drop: lowlevel_erbbands_kurtosis_dvar2 with VIF = 52.14528158402297\n",
      "drop: lowlevel_erbbands_kurtosis_var with VIF = 10.676452643892514\n",
      "drop: lowlevel_erbbands_skewness_dvar with VIF = 20.4533211602686\n",
      "drop: lowlevel_erbbands_skewness_dvar2 with VIF = 19.766511993452728\n",
      "drop: lowlevel_erbbands_skewness_var with VIF = 13.400626061057402\n",
      "drop: lowlevel_erbbands_spread_dmean with VIF = 25.69185477581947\n",
      "drop: lowlevel_erbbands_spread_dmean2 with VIF = 24.67721714732877\n",
      "drop: lowlevel_erbbands_spread_dvar with VIF = 38.651783181943955\n",
      "drop: lowlevel_erbbands_spread_dvar2 with VIF = 14.316901265684566\n",
      "drop: lowlevel_erbbands_spread_mean with VIF = 10.010196432859491\n",
      "drop: lowlevel_erbbands_spread_stdev with VIF = 21.67568588063061\n",
      "drop: lowlevel_hfc_dmean with VIF = 11.898041688604833\n",
      "drop: lowlevel_hfc_dmean2 with VIF = 12.189987602626125\n",
      "drop: lowlevel_hfc_dvar with VIF = 33839.755532883886\n",
      "drop: lowlevel_hfc_dvar2 with VIF = 29301.90173152656\n",
      "drop: lowlevel_hfc_max with VIF = 11.943176927740796\n",
      "drop: lowlevel_hfc_mean with VIF = 11.707063678022251\n",
      "drop: lowlevel_hfc_stdev with VIF = 46.752194788413156\n",
      "drop: lowlevel_hfc_var with VIF = 198.86404071128405\n",
      "drop: lowlevel_loudness_ebu128_momentary_dvar with VIF = 14.987287981274529\n",
      "drop: lowlevel_loudness_ebu128_momentary_dvar2 with VIF = 13.332967472554904\n",
      "drop: lowlevel_loudness_ebu128_momentary_mean with VIF = 15.134207239771166\n",
      "drop: lowlevel_loudness_ebu128_momentary_median with VIF = 10.040842095688562\n",
      "drop: lowlevel_loudness_ebu128_momentary_stdev with VIF = 48.626238267666785\n",
      "drop: lowlevel_loudness_ebu128_momentary_var with VIF = 111.69333330623262\n",
      "drop: lowlevel_loudness_ebu128_short_term_mean with VIF = 10.375002253563487\n",
      "drop: lowlevel_loudness_ebu128_short_term_stdev with VIF = 10.620402005021987\n",
      "drop: lowlevel_melbands_flatness_db_mean with VIF = 14.806007852495988\n",
      "drop: lowlevel_melbands_flatness_db_median with VIF = 12.75240156334765\n",
      "drop: lowlevel_melbands_flatness_db_stdev with VIF = 12.379045488079294\n",
      "drop: lowlevel_melbands_flatness_db_var with VIF = 11.87281932451347\n",
      "drop: lowlevel_melbands_kurtosis_dmean with VIF = 3742604605.1845136\n",
      "drop: lowlevel_melbands_kurtosis_dmean2 with VIF = 5148056507.195513\n",
      "drop: lowlevel_melbands_kurtosis_dvar with VIF = 1178774577.2387803\n",
      "drop: lowlevel_melbands_kurtosis_dvar2 with VIF = 870614174.3852738\n",
      "drop: lowlevel_melbands_kurtosis_max with VIF = 494366.3165761729\n",
      "drop: lowlevel_melbands_kurtosis_mean with VIF = 710349745.4438695\n",
      "drop: lowlevel_melbands_kurtosis_median with VIF = 51.55148342437786\n",
      "drop: lowlevel_melbands_kurtosis_stdev with VIF = 2569111.0722616706\n",
      "drop: lowlevel_melbands_kurtosis_var with VIF = 37679579.80262659\n",
      "drop: lowlevel_melbands_skewness_dmean with VIF = 45989.777772959955\n",
      "drop: lowlevel_melbands_skewness_dmean2 with VIF = 51535.42393782202\n",
      "drop: lowlevel_melbands_skewness_dvar with VIF = 487980925.3760554\n",
      "drop: lowlevel_melbands_skewness_dvar2 with VIF = 685173257.4236422\n",
      "drop: lowlevel_melbands_skewness_max with VIF = 2469.3045881171415\n",
      "drop: lowlevel_melbands_skewness_mean with VIF = 105256.7492743828\n",
      "drop: lowlevel_melbands_skewness_stdev with VIF = 18686.814379515574\n",
      "drop: lowlevel_melbands_skewness_var with VIF = 66321559.11593478\n",
      "drop: lowlevel_melbands_spread_dmean with VIF = 29.259738655752894\n",
      "drop: lowlevel_melbands_spread_dmean2 with VIF = 28.47916232068047\n",
      "drop: lowlevel_melbands_spread_dvar with VIF = 114.55523072009521\n",
      "drop: lowlevel_melbands_spread_dvar2 with VIF = 13.141853566856874\n",
      "drop: lowlevel_melbands_spread_mean with VIF = 22.877039094831865\n",
      "drop: lowlevel_melbands_spread_median with VIF = 14.358052301376944\n",
      "drop: lowlevel_melbands_spread_stdev with VIF = 45.242926388337516\n",
      "drop: lowlevel_melbands_spread_var with VIF = 13.045678435815322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/statsmodels/regression/linear_model.py:1685: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    }
   ],
   "source": [
    "#vif = pd.DataFrame()\n",
    "#vif[\"VIF Factor\"] = [variance_inflation_factor(train_df.values, i) for i in range(train_df.shape[1])]\n",
    "#vif[\"features\"] = train_df.columns\n",
    "X=train_df\n",
    "vif = pd.DataFrame()\n",
    "drop = pd.DataFrame()\n",
    "keep = pd.DataFrame()\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    vif_amount = variance_inflation_factor(X.values, i)\n",
    "    vif[\"VIF Factor\"] = vif_amount\n",
    "    vif_column = X.columns[i]\n",
    "    vif[\"features\"] = vif_column\n",
    "\n",
    "    if vif_amount > 10:\n",
    "        drop[\"VIF Factor\"] = vif_amount\n",
    "        drop[\"features\"] = vif_column\n",
    "        print('drop: ' + vif_column + ' with VIF = ' + str(vif_amount))\n",
    "    else:\n",
    "        keep[\"VIF Factor\"] = vif_amount\n",
    "        keep[\"features\"] = vif_column  \n",
    "        \n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n",
    "    print(\"Keep These Columns\")\n",
    "    print(\"**************************************\")\n",
    "    keep.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif2(X, thresh=10):\n",
    "    # For each X, calculate VIF and save in dataframe\n",
    "    vif = pd.DataFrame()\n",
    "    drop = pd.DataFrame()\n",
    "    keep = pd.DataFrame()\n",
    "\n",
    "    for i in range(X.shape[1]):\n",
    "        vif_amount = variance_inflation_factor(X.values, i)\n",
    "        vif[\"VIF Factor\"] = vif_amount\n",
    "        vif_column = X.columns[i]\n",
    "        vif[\"features\"] = vif_column\n",
    "\n",
    "        if vif_amount > thresh:\n",
    "            drop[\"VIF Factor\"] = vif_amount\n",
    "            drop[\"features\"] = vif_column\n",
    "            print('drop: ' + vif_column + ' with VIF = ' + str(vif_amount))\n",
    "        else:\n",
    "            keep[\"VIF Factor\"] = vif_amount\n",
    "            keep[\"features\"] = vif_column   \n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove multicollinearity\n",
    "\n",
    "#find the number of CPUs and set the pool\n",
    "#reduce total core count by 2 to prevent saturation\n",
    "cores = mp.cpu_count()\n",
    "pool = Pool(cores)\n",
    "\n",
    "#create new dataframe, split it by core, create a process to run VIF\n",
    "train_df_split = pd.DataFrame(train_df) \n",
    "train_df_split = np.array_split(train_df, cores, axis=0)\n",
    "vif = np.vstack(pool.map(calculate_vif2, train_df_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure to use stratification\n",
    "#to balance class representations\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df, labels, test_size=0.25, \n",
    "                                                    random_state=42, stratify=labels)\n",
    "\n",
    "#seperate out scale operations to avoid data leakage\n",
    "scaler = StandardScaler()\n",
    "music_scaled_X_train = scaler.fit_transform(X_train)\n",
    "music_scaled_X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCs = 1491\n",
      "Cumulative Variance = 0.9906386337179818\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(music_scaled, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "#initialize search values for optimal k\n",
    "i = 1490\n",
    "variance_explained = 0\n",
    "target_variance_percentile = 0.99\n",
    "\n",
    "#find the optimal k\n",
    "while variance_explained <= target_variance_percentile:\n",
    "    i=i+1\n",
    "    pca = PCA(n_components=i)\n",
    "    forest = RandomForestClassifier(n_estimators=100)\n",
    "    pipe = Pipeline(steps=[('pca', pca), ('forest', forest)])\n",
    "    pipe.fit(music_scaled_X_train, y_train)\n",
    "    pca_variance_explained = np.cumsum(pca.explained_variance_ratio_)\n",
    "    \n",
    "    array_length = len(pca_variance_explained)\n",
    "    variance_explained = pca_variance_explained[array_length - 1]\n",
    "    \n",
    "    if variance_explained > target_variance_percentile-0.19:\n",
    "        print('PCs = '+ str(i))\n",
    "        print('Cumulative Variance = '+ str(variance_explained))\n",
    "        \n",
    "    \n",
    "#final PCA model\n",
    "pca = PCA(n_components=i)\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "pipe = Pipeline(steps=[('pca', pca), ('forest', forest)])\n",
    "pipe.fit(music_scaled_X_train, y_train)\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with RandomForest: 26.655552%\n"
     ]
    }
   ],
   "source": [
    "test_predictions = pipe.predict(music_scaled_X_test)\n",
    "precision = accuracy_score(test_predictions, y_test) * 100\n",
    "print(\"Accuracy with RandomForest: {0:.6f}%\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 1 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=25.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 25.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=30.4min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=42.7min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=27.7min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=37.4min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=25.0min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=37.2min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=31.1min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=32.5min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=36.6min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=31.2min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=31.7min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=36.8min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=34.6min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=28.2min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=28.6min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=34.2min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=25.2min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=24.9min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=38.5min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=26.4min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=36.8min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=32.9min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=31.2min\n",
      "[CV] forest__n_estimators=100, pca__n_components=1491 ................\n",
      "[CV] . forest__n_estimators=100, pca__n_components=1491, total=24.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed: 791.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=5, n_splits=5, random_state=None),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('pca',\n",
       "                                        PCA(copy=True, iterated_power='auto',\n",
       "                                            n_components=1491,\n",
       "                                            random_state=None,\n",
       "                                            svd_solver='auto', tol=0.0,\n",
       "                                            whiten=False)),\n",
       "                                       ('forest',\n",
       "                                        RandomForestClassifier(bootstrap=True,\n",
       "                                                               ccp_alpha=0.0,\n",
       "                                                               class_weight=None,\n",
       "                                                               criterion='gin...\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'forest__n_estimators': [100],\n",
       "                         'pca__n_components': [1491]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "param_dict = {\"pca__n_components\":[1491],\n",
    "              \"forest__n_estimators\":[100]}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "estimator = GridSearchCV(pipe,\n",
    "                         param_dict,\n",
    "                         cv=cv,\n",
    "                         verbose=2)\n",
    "\n",
    "estimator.fit(music_scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters: {'forest__n_estimators': 100, 'pca__n_components': 1491}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameters: {0}\".format(estimator.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with RandomForest: 26.655552%\n"
     ]
    }
   ],
   "source": [
    "test_predictions = pipe.predict(music_scaled_X_test)\n",
    "precision = accuracy_score(test_predictions, y_test) * 100\n",
    "print(\"Accuracy with RandomForest: {0:.6f}%\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with RandomForest: 100.000000%\n"
     ]
    }
   ],
   "source": [
    "pipe.set_params(**estimator.best_params_);\n",
    "pipe.fit(music_scaled_X_train, y_train);\n",
    "\n",
    "test_predictions = pipe.predict(music_scaled_X_train)\n",
    "precision = accuracy_score(test_predictions, y_train) * 100\n",
    "print(\"Accuracy with RandomForest: {0:.6f}%\".format(precision))\n",
    "\n",
    "#test_df = pd.read_csv(\"../input/sign_mnist_test.csv\", header=0)\n",
    "#test_labels = test_df[\"genre\"].values\n",
    "#test_df.drop([\"genre\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a PCA based training frame\n",
    "pca = PCA(n_components=i)\n",
    "new_dataframe_pipe = Pipeline(steps=[('pca', pca)])\n",
    "\n",
    "principle_components = new_dataframe_pipe.fit_transform(music_scaled_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1482</th>\n",
       "      <th>1483</th>\n",
       "      <th>1484</th>\n",
       "      <th>1485</th>\n",
       "      <th>1486</th>\n",
       "      <th>1487</th>\n",
       "      <th>1488</th>\n",
       "      <th>1489</th>\n",
       "      <th>1490</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.229566</td>\n",
       "      <td>-1.902976</td>\n",
       "      <td>3.037285</td>\n",
       "      <td>18.022181</td>\n",
       "      <td>21.257472</td>\n",
       "      <td>1.006087</td>\n",
       "      <td>0.183701</td>\n",
       "      <td>-2.782119</td>\n",
       "      <td>1.668758</td>\n",
       "      <td>1.340693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228574</td>\n",
       "      <td>0.010443</td>\n",
       "      <td>-0.001056</td>\n",
       "      <td>0.419442</td>\n",
       "      <td>-0.184098</td>\n",
       "      <td>-0.072992</td>\n",
       "      <td>0.123720</td>\n",
       "      <td>-0.102825</td>\n",
       "      <td>-0.326741</td>\n",
       "      <td>Dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.708711</td>\n",
       "      <td>-29.185892</td>\n",
       "      <td>22.037479</td>\n",
       "      <td>-9.259812</td>\n",
       "      <td>-8.090364</td>\n",
       "      <td>-3.166292</td>\n",
       "      <td>3.816111</td>\n",
       "      <td>-3.119004</td>\n",
       "      <td>14.542073</td>\n",
       "      <td>-4.394920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453821</td>\n",
       "      <td>0.308777</td>\n",
       "      <td>0.059496</td>\n",
       "      <td>0.552813</td>\n",
       "      <td>-0.621987</td>\n",
       "      <td>0.025122</td>\n",
       "      <td>-0.241435</td>\n",
       "      <td>0.073065</td>\n",
       "      <td>0.038185</td>\n",
       "      <td>Blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.752665</td>\n",
       "      <td>19.815111</td>\n",
       "      <td>-20.657853</td>\n",
       "      <td>21.031589</td>\n",
       "      <td>-16.931611</td>\n",
       "      <td>7.285425</td>\n",
       "      <td>-4.522447</td>\n",
       "      <td>-1.378319</td>\n",
       "      <td>4.427535</td>\n",
       "      <td>-0.859046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280570</td>\n",
       "      <td>-0.103462</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>-0.322019</td>\n",
       "      <td>-0.417513</td>\n",
       "      <td>0.784926</td>\n",
       "      <td>-0.529272</td>\n",
       "      <td>-0.652729</td>\n",
       "      <td>-0.321636</td>\n",
       "      <td>Lo-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.348096</td>\n",
       "      <td>4.031171</td>\n",
       "      <td>0.986149</td>\n",
       "      <td>-14.371868</td>\n",
       "      <td>2.033340</td>\n",
       "      <td>-0.350750</td>\n",
       "      <td>-2.541646</td>\n",
       "      <td>13.540084</td>\n",
       "      <td>-1.586789</td>\n",
       "      <td>-2.249359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193042</td>\n",
       "      <td>0.518493</td>\n",
       "      <td>-0.597468</td>\n",
       "      <td>-0.144503</td>\n",
       "      <td>-0.056426</td>\n",
       "      <td>0.191189</td>\n",
       "      <td>0.403946</td>\n",
       "      <td>-0.380171</td>\n",
       "      <td>-0.057189</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-12.108964</td>\n",
       "      <td>12.803063</td>\n",
       "      <td>-11.596527</td>\n",
       "      <td>13.932410</td>\n",
       "      <td>-6.100534</td>\n",
       "      <td>-13.652660</td>\n",
       "      <td>-1.072243</td>\n",
       "      <td>-9.988401</td>\n",
       "      <td>-13.017333</td>\n",
       "      <td>4.815079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097341</td>\n",
       "      <td>0.150458</td>\n",
       "      <td>-0.057403</td>\n",
       "      <td>-0.222646</td>\n",
       "      <td>-0.524074</td>\n",
       "      <td>0.217973</td>\n",
       "      <td>-0.143639</td>\n",
       "      <td>-0.274314</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44977</th>\n",
       "      <td>-9.777618</td>\n",
       "      <td>2.642785</td>\n",
       "      <td>5.614356</td>\n",
       "      <td>-30.916124</td>\n",
       "      <td>4.020509</td>\n",
       "      <td>-2.649198</td>\n",
       "      <td>2.593310</td>\n",
       "      <td>4.168512</td>\n",
       "      <td>-6.490480</td>\n",
       "      <td>0.873398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175597</td>\n",
       "      <td>-0.313006</td>\n",
       "      <td>0.687264</td>\n",
       "      <td>-0.471401</td>\n",
       "      <td>-0.269720</td>\n",
       "      <td>-0.454850</td>\n",
       "      <td>0.160136</td>\n",
       "      <td>-0.196080</td>\n",
       "      <td>0.700888</td>\n",
       "      <td>Sound Effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44978</th>\n",
       "      <td>-13.280689</td>\n",
       "      <td>18.285602</td>\n",
       "      <td>-15.121585</td>\n",
       "      <td>-10.902819</td>\n",
       "      <td>-22.151387</td>\n",
       "      <td>20.688480</td>\n",
       "      <td>-1.606905</td>\n",
       "      <td>1.863389</td>\n",
       "      <td>13.749705</td>\n",
       "      <td>-7.407014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133297</td>\n",
       "      <td>-0.473519</td>\n",
       "      <td>0.104891</td>\n",
       "      <td>-0.035579</td>\n",
       "      <td>-0.088967</td>\n",
       "      <td>-0.254515</td>\n",
       "      <td>0.261747</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>0.063559</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44979</th>\n",
       "      <td>-11.713129</td>\n",
       "      <td>9.575915</td>\n",
       "      <td>-4.004367</td>\n",
       "      <td>-13.279178</td>\n",
       "      <td>0.218279</td>\n",
       "      <td>-5.343600</td>\n",
       "      <td>-1.719235</td>\n",
       "      <td>5.906451</td>\n",
       "      <td>-14.362502</td>\n",
       "      <td>2.131165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.408691</td>\n",
       "      <td>0.278011</td>\n",
       "      <td>-0.022812</td>\n",
       "      <td>-0.302458</td>\n",
       "      <td>0.209981</td>\n",
       "      <td>0.346577</td>\n",
       "      <td>0.381633</td>\n",
       "      <td>0.191565</td>\n",
       "      <td>-0.152279</td>\n",
       "      <td>Avant-Garde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44980</th>\n",
       "      <td>4.021504</td>\n",
       "      <td>-21.107037</td>\n",
       "      <td>13.970044</td>\n",
       "      <td>6.639637</td>\n",
       "      <td>-8.075200</td>\n",
       "      <td>-5.578126</td>\n",
       "      <td>1.501612</td>\n",
       "      <td>-6.407242</td>\n",
       "      <td>14.549367</td>\n",
       "      <td>-3.653486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121070</td>\n",
       "      <td>-0.031390</td>\n",
       "      <td>-0.281367</td>\n",
       "      <td>0.064026</td>\n",
       "      <td>0.046392</td>\n",
       "      <td>0.800515</td>\n",
       "      <td>0.121373</td>\n",
       "      <td>-0.219115</td>\n",
       "      <td>1.124192</td>\n",
       "      <td>Experimental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44981</th>\n",
       "      <td>-4.845867</td>\n",
       "      <td>-10.444163</td>\n",
       "      <td>15.553525</td>\n",
       "      <td>-18.436424</td>\n",
       "      <td>15.322341</td>\n",
       "      <td>0.511123</td>\n",
       "      <td>4.022197</td>\n",
       "      <td>-1.972902</td>\n",
       "      <td>5.649943</td>\n",
       "      <td>-2.399730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140460</td>\n",
       "      <td>-0.151110</td>\n",
       "      <td>0.020928</td>\n",
       "      <td>0.447009</td>\n",
       "      <td>-0.098641</td>\n",
       "      <td>-0.237746</td>\n",
       "      <td>0.210435</td>\n",
       "      <td>0.053395</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44982 rows Ã— 1492 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4          5  \\\n",
       "0      -8.229566  -1.902976   3.037285  18.022181  21.257472   1.006087   \n",
       "1       8.708711 -29.185892  22.037479  -9.259812  -8.090364  -3.166292   \n",
       "2     -13.752665  19.815111 -20.657853  21.031589 -16.931611   7.285425   \n",
       "3      -9.348096   4.031171   0.986149 -14.371868   2.033340  -0.350750   \n",
       "4     -12.108964  12.803063 -11.596527  13.932410  -6.100534 -13.652660   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "44977  -9.777618   2.642785   5.614356 -30.916124   4.020509  -2.649198   \n",
       "44978 -13.280689  18.285602 -15.121585 -10.902819 -22.151387  20.688480   \n",
       "44979 -11.713129   9.575915  -4.004367 -13.279178   0.218279  -5.343600   \n",
       "44980   4.021504 -21.107037  13.970044   6.639637  -8.075200  -5.578126   \n",
       "44981  -4.845867 -10.444163  15.553525 -18.436424  15.322341   0.511123   \n",
       "\n",
       "              6          7          8         9  ...      1482      1483  \\\n",
       "0      0.183701  -2.782119   1.668758  1.340693  ...  0.228574  0.010443   \n",
       "1      3.816111  -3.119004  14.542073 -4.394920  ...  0.453821  0.308777   \n",
       "2     -4.522447  -1.378319   4.427535 -0.859046  ...  0.280570 -0.103462   \n",
       "3     -2.541646  13.540084  -1.586789 -2.249359  ... -0.193042  0.518493   \n",
       "4     -1.072243  -9.988401 -13.017333  4.815079  ...  0.097341  0.150458   \n",
       "...         ...        ...        ...       ...  ...       ...       ...   \n",
       "44977  2.593310   4.168512  -6.490480  0.873398  ... -0.175597 -0.313006   \n",
       "44978 -1.606905   1.863389  13.749705 -7.407014  ... -0.133297 -0.473519   \n",
       "44979 -1.719235   5.906451 -14.362502  2.131165  ... -0.408691  0.278011   \n",
       "44980  1.501612  -6.407242  14.549367 -3.653486  ...  0.121070 -0.031390   \n",
       "44981  4.022197  -1.972902   5.649943 -2.399730  ... -0.140460 -0.151110   \n",
       "\n",
       "           1484      1485      1486      1487      1488      1489      1490  \\\n",
       "0     -0.001056  0.419442 -0.184098 -0.072992  0.123720 -0.102825 -0.326741   \n",
       "1      0.059496  0.552813 -0.621987  0.025122 -0.241435  0.073065  0.038185   \n",
       "2      0.084399 -0.322019 -0.417513  0.784926 -0.529272 -0.652729 -0.321636   \n",
       "3     -0.597468 -0.144503 -0.056426  0.191189  0.403946 -0.380171 -0.057189   \n",
       "4     -0.057403 -0.222646 -0.524074  0.217973 -0.143639 -0.274314  0.019272   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "44977  0.687264 -0.471401 -0.269720 -0.454850  0.160136 -0.196080  0.700888   \n",
       "44978  0.104891 -0.035579 -0.088967 -0.254515  0.261747  0.003016  0.063559   \n",
       "44979 -0.022812 -0.302458  0.209981  0.346577  0.381633  0.191565 -0.152279   \n",
       "44980 -0.281367  0.064026  0.046392  0.800515  0.121373 -0.219115  1.124192   \n",
       "44981  0.020928  0.447009 -0.098641 -0.237746  0.210435  0.053395  0.003501   \n",
       "\n",
       "               genre  \n",
       "0              Dance  \n",
       "1              Blues  \n",
       "2              Lo-Fi  \n",
       "3              Noise  \n",
       "4              Noise  \n",
       "...              ...  \n",
       "44977  Sound Effects  \n",
       "44978            Pop  \n",
       "44979    Avant-Garde  \n",
       "44980   Experimental  \n",
       "44981     Electronic  \n",
       "\n",
       "[44982 rows x 1492 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_scaled_X_train_pca = pd.DataFrame(data = principle_components)\n",
    "music_scaled_y_train = pd.DataFrame(data = y_train, columns = ['genre'])\n",
    "music_scaled_X_train_pca = pd.concat([music_scaled_X_train_pca, music_scaled_y_train], axis=1)\n",
    "music_scaled_X_train_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a PCA based test frame\n",
    "pca = PCA(n_components=i)\n",
    "new_dataframe_pipe = Pipeline(steps=[('pca', pca)])\n",
    "\n",
    "principle_components = new_dataframe_pipe.fit_transform(music_scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1482</th>\n",
       "      <th>1483</th>\n",
       "      <th>1484</th>\n",
       "      <th>1485</th>\n",
       "      <th>1486</th>\n",
       "      <th>1487</th>\n",
       "      <th>1488</th>\n",
       "      <th>1489</th>\n",
       "      <th>1490</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.970117</td>\n",
       "      <td>6.818098</td>\n",
       "      <td>-7.727968</td>\n",
       "      <td>0.095977</td>\n",
       "      <td>9.599847</td>\n",
       "      <td>-5.789358</td>\n",
       "      <td>3.666374</td>\n",
       "      <td>13.480109</td>\n",
       "      <td>-3.578910</td>\n",
       "      <td>1.325185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.198882</td>\n",
       "      <td>0.387862</td>\n",
       "      <td>-0.026338</td>\n",
       "      <td>-0.028133</td>\n",
       "      <td>-0.123839</td>\n",
       "      <td>-0.151713</td>\n",
       "      <td>0.094398</td>\n",
       "      <td>-0.015197</td>\n",
       "      <td>Avant-Garde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.741736</td>\n",
       "      <td>-14.142398</td>\n",
       "      <td>15.763048</td>\n",
       "      <td>-10.905533</td>\n",
       "      <td>4.526840</td>\n",
       "      <td>-8.195744</td>\n",
       "      <td>-4.857452</td>\n",
       "      <td>-7.094710</td>\n",
       "      <td>11.574013</td>\n",
       "      <td>-3.303492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174258</td>\n",
       "      <td>-0.379888</td>\n",
       "      <td>0.336483</td>\n",
       "      <td>0.081884</td>\n",
       "      <td>-0.042575</td>\n",
       "      <td>0.106668</td>\n",
       "      <td>0.100321</td>\n",
       "      <td>-0.081981</td>\n",
       "      <td>-0.259148</td>\n",
       "      <td>Field Recordings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-12.630795</td>\n",
       "      <td>10.135627</td>\n",
       "      <td>-11.454185</td>\n",
       "      <td>19.070447</td>\n",
       "      <td>7.868272</td>\n",
       "      <td>-12.412734</td>\n",
       "      <td>14.734534</td>\n",
       "      <td>-11.875378</td>\n",
       "      <td>-8.874652</td>\n",
       "      <td>7.573865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465060</td>\n",
       "      <td>-0.019583</td>\n",
       "      <td>0.041220</td>\n",
       "      <td>-0.246864</td>\n",
       "      <td>0.294334</td>\n",
       "      <td>-0.217686</td>\n",
       "      <td>0.431887</td>\n",
       "      <td>0.081434</td>\n",
       "      <td>-0.150288</td>\n",
       "      <td>Hardcore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.915803</td>\n",
       "      <td>3.424928</td>\n",
       "      <td>-2.428944</td>\n",
       "      <td>16.175840</td>\n",
       "      <td>-12.404964</td>\n",
       "      <td>-2.568919</td>\n",
       "      <td>10.324103</td>\n",
       "      <td>-21.658444</td>\n",
       "      <td>-2.300490</td>\n",
       "      <td>3.106268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234332</td>\n",
       "      <td>0.100599</td>\n",
       "      <td>0.019114</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.388499</td>\n",
       "      <td>0.556807</td>\n",
       "      <td>-0.227037</td>\n",
       "      <td>-0.074297</td>\n",
       "      <td>-0.103726</td>\n",
       "      <td>Psych-Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-13.008905</td>\n",
       "      <td>13.775277</td>\n",
       "      <td>-15.799405</td>\n",
       "      <td>-4.547360</td>\n",
       "      <td>10.197738</td>\n",
       "      <td>17.332156</td>\n",
       "      <td>-13.149110</td>\n",
       "      <td>-9.038606</td>\n",
       "      <td>-2.447433</td>\n",
       "      <td>-2.041262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076114</td>\n",
       "      <td>-0.411103</td>\n",
       "      <td>-0.155054</td>\n",
       "      <td>-0.767226</td>\n",
       "      <td>-0.284188</td>\n",
       "      <td>0.576808</td>\n",
       "      <td>-0.264049</td>\n",
       "      <td>-0.016502</td>\n",
       "      <td>-0.072704</td>\n",
       "      <td>Experimental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>-10.161986</td>\n",
       "      <td>1.083542</td>\n",
       "      <td>1.128377</td>\n",
       "      <td>-1.998601</td>\n",
       "      <td>-29.240473</td>\n",
       "      <td>12.240181</td>\n",
       "      <td>6.925883</td>\n",
       "      <td>-0.761301</td>\n",
       "      <td>-15.977577</td>\n",
       "      <td>6.482080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245610</td>\n",
       "      <td>0.386643</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>0.097861</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.454216</td>\n",
       "      <td>0.185311</td>\n",
       "      <td>0.360890</td>\n",
       "      <td>0.039252</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>6.130013</td>\n",
       "      <td>-14.596104</td>\n",
       "      <td>12.506165</td>\n",
       "      <td>28.972567</td>\n",
       "      <td>15.379388</td>\n",
       "      <td>-11.309574</td>\n",
       "      <td>-8.480112</td>\n",
       "      <td>-10.311934</td>\n",
       "      <td>11.082353</td>\n",
       "      <td>-3.785830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041718</td>\n",
       "      <td>0.050411</td>\n",
       "      <td>-0.012143</td>\n",
       "      <td>-0.138870</td>\n",
       "      <td>0.251190</td>\n",
       "      <td>0.066301</td>\n",
       "      <td>-0.216829</td>\n",
       "      <td>0.271870</td>\n",
       "      <td>0.438329</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>-11.357183</td>\n",
       "      <td>4.869451</td>\n",
       "      <td>-4.130611</td>\n",
       "      <td>2.305854</td>\n",
       "      <td>-20.027844</td>\n",
       "      <td>10.976603</td>\n",
       "      <td>6.156500</td>\n",
       "      <td>1.667980</td>\n",
       "      <td>-18.094796</td>\n",
       "      <td>6.776717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180374</td>\n",
       "      <td>0.070330</td>\n",
       "      <td>-0.119262</td>\n",
       "      <td>0.113081</td>\n",
       "      <td>0.335141</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>-0.101561</td>\n",
       "      <td>-0.416061</td>\n",
       "      <td>-0.035205</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>-8.716091</td>\n",
       "      <td>1.455538</td>\n",
       "      <td>-1.104800</td>\n",
       "      <td>13.955678</td>\n",
       "      <td>-0.096473</td>\n",
       "      <td>-13.273280</td>\n",
       "      <td>11.526349</td>\n",
       "      <td>-12.164125</td>\n",
       "      <td>1.198580</td>\n",
       "      <td>0.769808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169462</td>\n",
       "      <td>0.100773</td>\n",
       "      <td>-0.055010</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>-0.156574</td>\n",
       "      <td>-0.147824</td>\n",
       "      <td>0.047352</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>-0.011205</td>\n",
       "      <td>Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>-12.798617</td>\n",
       "      <td>10.368780</td>\n",
       "      <td>-11.111015</td>\n",
       "      <td>1.580670</td>\n",
       "      <td>-8.145269</td>\n",
       "      <td>22.801906</td>\n",
       "      <td>-10.067387</td>\n",
       "      <td>-1.694465</td>\n",
       "      <td>-9.737911</td>\n",
       "      <td>0.368761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045783</td>\n",
       "      <td>-0.675390</td>\n",
       "      <td>0.343274</td>\n",
       "      <td>-0.163469</td>\n",
       "      <td>0.035507</td>\n",
       "      <td>-0.443634</td>\n",
       "      <td>-0.051591</td>\n",
       "      <td>-0.074756</td>\n",
       "      <td>0.340010</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14995 rows Ã— 1492 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4          5  \\\n",
       "0      -9.970117   6.818098  -7.727968   0.095977   9.599847  -5.789358   \n",
       "1       2.741736 -14.142398  15.763048 -10.905533   4.526840  -8.195744   \n",
       "2     -12.630795  10.135627 -11.454185  19.070447   7.868272 -12.412734   \n",
       "3     -10.915803   3.424928  -2.428944  16.175840 -12.404964  -2.568919   \n",
       "4     -13.008905  13.775277 -15.799405  -4.547360  10.197738  17.332156   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "14990 -10.161986   1.083542   1.128377  -1.998601 -29.240473  12.240181   \n",
       "14991   6.130013 -14.596104  12.506165  28.972567  15.379388 -11.309574   \n",
       "14992 -11.357183   4.869451  -4.130611   2.305854 -20.027844  10.976603   \n",
       "14993  -8.716091   1.455538  -1.104800  13.955678  -0.096473 -13.273280   \n",
       "14994 -12.798617  10.368780 -11.111015   1.580670  -8.145269  22.801906   \n",
       "\n",
       "               6          7          8         9  ...      1482      1483  \\\n",
       "0       3.666374  13.480109  -3.578910  1.325185  ...  0.001233  0.198882   \n",
       "1      -4.857452  -7.094710  11.574013 -3.303492  ...  0.174258 -0.379888   \n",
       "2      14.734534 -11.875378  -8.874652  7.573865  ...  0.465060 -0.019583   \n",
       "3      10.324103 -21.658444  -2.300490  3.106268  ...  0.234332  0.100599   \n",
       "4     -13.149110  -9.038606  -2.447433 -2.041262  ... -0.076114 -0.411103   \n",
       "...          ...        ...        ...       ...  ...       ...       ...   \n",
       "14990   6.925883  -0.761301 -15.977577  6.482080  ... -0.245610  0.386643   \n",
       "14991  -8.480112 -10.311934  11.082353 -3.785830  ...  0.041718  0.050411   \n",
       "14992   6.156500   1.667980 -18.094796  6.776717  ... -0.180374  0.070330   \n",
       "14993  11.526349 -12.164125   1.198580  0.769808  ...  0.169462  0.100773   \n",
       "14994 -10.067387  -1.694465  -9.737911  0.368761  ... -0.045783 -0.675390   \n",
       "\n",
       "           1484      1485      1486      1487      1488      1489      1490  \\\n",
       "0      0.387862 -0.026338 -0.028133 -0.123839 -0.151713  0.094398 -0.015197   \n",
       "1      0.336483  0.081884 -0.042575  0.106668  0.100321 -0.081981 -0.259148   \n",
       "2      0.041220 -0.246864  0.294334 -0.217686  0.431887  0.081434 -0.150288   \n",
       "3      0.019114  0.288785 -0.388499  0.556807 -0.227037 -0.074297 -0.103726   \n",
       "4     -0.155054 -0.767226 -0.284188  0.576808 -0.264049 -0.016502 -0.072704   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14990  0.090495  0.097861 -0.040533  0.454216  0.185311  0.360890  0.039252   \n",
       "14991 -0.012143 -0.138870  0.251190  0.066301 -0.216829  0.271870  0.438329   \n",
       "14992 -0.119262  0.113081  0.335141  0.017977 -0.101561 -0.416061 -0.035205   \n",
       "14993 -0.055010  0.001553 -0.156574 -0.147824  0.047352  0.008533 -0.011205   \n",
       "14994  0.343274 -0.163469  0.035507 -0.443634 -0.051591 -0.074756  0.340010   \n",
       "\n",
       "                  genre  \n",
       "0           Avant-Garde  \n",
       "1      Field Recordings  \n",
       "2              Hardcore  \n",
       "3            Psych-Rock  \n",
       "4          Experimental  \n",
       "...                 ...  \n",
       "14990        Electronic  \n",
       "14991     International  \n",
       "14992           Hip-Hop  \n",
       "14993             Metal  \n",
       "14994           Hip-Hop  \n",
       "\n",
       "[14995 rows x 1492 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_scaled_X_test_pca = pd.DataFrame(data = principle_components)\n",
    "music_scaled_y_test = pd.DataFrame(data = y_test, columns = ['genre'])\n",
    "music_scaled_X_test_pca = pd.concat([music_scaled_X_test_pca, music_scaled_y_test], axis=1)\n",
    "music_scaled_X_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export pca training dataframe\n",
    "music_scaled_X_train_pca.to_csv('music_scaled_train_pca_vif_75.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export PCA based testing dataframe\n",
    "music_scaled_X_test_pca.to_csv('music_scaled_test_pca_vif_25.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#### EXPERIMENTAL\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "pipe.set_params(**estimator.best_params_)\n",
    "result = permutation_importance(pipe, music_scaled_X_train, y_train, \n",
    "                                n_repeats=10,\n",
    "                                random_state=42)\n",
    "\n",
    "perm_sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "tree_importance_sorted_idx = np.argsort(clf.feature_importances_)\n",
    "tree_indices = np.arange(0, len(clf.feature_importances_)) + 0.5\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "ax1.barh(tree_indices,\n",
    "         clf.feature_importances_[tree_importance_sorted_idx], height=0.7)\n",
    "ax1.set_yticklabels(data.feature_names[tree_importance_sorted_idx])\n",
    "ax1.set_yticks(tree_indices)\n",
    "ax1.set_ylim((0, len(clf.feature_importances_)))\n",
    "ax2.boxplot(result.importances[perm_sorted_idx].T, vert=False,\n",
    "            labels=data.feature_names[perm_sorted_idx])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
